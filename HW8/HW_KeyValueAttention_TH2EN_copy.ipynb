{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "key_value_attention_mechanism_homework.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1cDcKRZwXCL"
      },
      "source": [
        "# Key-Value Attention Mechanism Homework on Keras: Character-level Machine Translation (Many-to-Many, encoder-decoder)\n",
        "\n",
        "In this homework, you will create an MT model with key-value attention mechnism that coverts names of constituency MP candidates in the 2019 Thai general election from Thai script to Roman(Latin) script. E.g. นิยม-->niyom "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy6QYsP4wa-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95bc1001-50a9-43e1-95da-42a9a5b983c4"
      },
      "source": [
        "!wget https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import matplotlib as mpl\n",
        "mpl.font_manager.fontManager.addfont('thsarabunnew-webfont.ttf') # 3.2+\n",
        "mpl.rc('font', family='TH Sarabun New')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-22 15:20:04--  https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Phonbopit/sarabun-webfont/master/fonts/thsarabunnew-webfont.ttf [following]\n",
            "--2021-03-22 15:20:04--  https://raw.githubusercontent.com/Phonbopit/sarabun-webfont/master/fonts/thsarabunnew-webfont.ttf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98308 (96K) [application/octet-stream]\n",
            "Saving to: ‘thsarabunnew-webfont.ttf’\n",
            "\n",
            "thsarabunnew-webfon 100%[===================>]  96.00K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-03-22 15:20:04 (9.86 MB/s) - ‘thsarabunnew-webfont.ttf’ saved [98308/98308]\n",
            "\n",
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRdbTrQJwXCR"
      },
      "source": [
        "%matplotlib inline\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
        "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq20keO6wXCh"
      },
      "source": [
        "## Load Dataset\n",
        "We have generated a toy dataset using names of constituency MP candidates in 2019 Thai General Election from elect.in.th's github(https://github.com/codeforthailand/dataset-election-62-candidates) and tltk (https://pypi.org/project/tltk/) library to convert them into Roman script.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/dataset_diagram.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8lWBh40wjgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a3b5215-64f6-4a26-b059-4d082359a9a9"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-22 15:20:06--  https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 324399 (317K) [text/plain]\n",
            "Saving to: ‘mp_name_th_en.csv’\n",
            "\n",
            "mp_name_th_en.csv   100%[===================>] 316.80K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-03-22 15:20:06 (13.5 MB/s) - ‘mp_name_th_en.csv’ saved [324399/324399]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTQk8W4OwXCk"
      },
      "source": [
        "import csv\n",
        "with open('mp_name_th_en.csv') as csvfile:\n",
        "    readCSV = csv.reader(csvfile, delimiter=',')\n",
        "    name_th = []\n",
        "    name_en = []\n",
        "    for row in readCSV:\n",
        "        name_th.append(row[0])\n",
        "        name_en.append(row[1])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVNHVM_FwXCs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54665697-ce33-4d9e-9d8e-dce1dab8303d"
      },
      "source": [
        "for th, en in zip(name_th[:10],name_en[:10]):\n",
        "    print(th,en)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ไกรสีห์ kraisi\n",
            "พัชรี phatri\n",
            "ธีระ thira\n",
            "วุฒิกร wutthikon\n",
            "ไสว sawai\n",
            "สัมภาษณ์  samphat\n",
            "วศิน wasin\n",
            "ทินวัฒน์ thinwat\n",
            "ศักดินัย sakdinai\n",
            "สุรศักดิ์ surasak\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heMTiM7qwXC2"
      },
      "source": [
        "## Task1: Preprocess dataset for Keras (1 point)\n",
        "* 2 dictionaries for indexing (1 for input and another for output)\n",
        "* DON'T FORGET TO INCLUDE special token for padding\n",
        "* DON'T FORGET TO INCLUDE special token for the end of word symbol (output)\n",
        "* Be mindful of your pad_sequences \"padding\" hyperparameter. Choose wisely (post-padding vs pre-padding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O5YhjntwXC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd1e54b-f47e-4717-f7aa-760bc98bda54"
      },
      "source": [
        "#FILL YOUR CODE HERE\n",
        "\n",
        "inputchar_th = sorted(list(set(''.join(name_th))))\n",
        "inputchar_th = [\"<PAD>\"] + inputchar_th\n",
        "\n",
        "outputchar_en = sorted(list(set(''.join(name_en))))\n",
        "outputchar_en = [\"<PAD>\", \"</s>\"] + outputchar_en\n",
        "\n",
        "\n",
        "inputchar2idx = { c:idx for idx, c in enumerate(inputchar_th)}\n",
        "idx2inputchar = { idx:c for idx, c in enumerate(inputchar_th)}\n",
        "\n",
        "outputchar2idx = { c:idx for idx, c in enumerate(outputchar_en)}\n",
        "idx2outputchar = { idx:c for idx, c in enumerate(outputchar_en)}\n",
        "\n",
        "print(input_char_th)\n",
        "print(output_char_en)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<PAD>', '<PAD>', '<PAD>', ' ', 'ก', 'ข', 'ค', 'ฆ', 'ง', 'จ', 'ฉ', 'ช', 'ซ', 'ฌ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท', 'ธ', 'น', 'บ', 'ป', 'ผ', 'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ล', 'ว', 'ศ', 'ษ', 'ส', 'ห', 'ฬ', 'อ', 'ฮ', 'ะ', 'ั', 'า', 'ำ', 'ิ', 'ี', 'ึ', 'ื', 'ุ', 'ู', 'เ', 'แ', 'โ', 'ใ', 'ไ', '็', '่', '้', '๊', '๋', '์']\n",
            "['<PAD>', '</s>', '-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'w', 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdTvQyH5jTsy",
        "outputId": "e1bc1085-fcc0-4252-defc-daf2456233a5"
      },
      "source": [
        "max_input = len(max(name_th, key=len))\n",
        "max_output = len(max(name_en, key=len))+1\n",
        "\n",
        "x = [[inputchar2idx[c] for c in name] for name in name_th]\n",
        "y = [[outputchar2idx[c] for c in name] for name in name_en]\n",
        "x = pad_sequences(x, maxlen=max_input)\n",
        "y = pad_sequences(y, maxlen=max_output)\n",
        "\n",
        "x = to_categorical(x, len(inputchar2idx))\n",
        "y = to_categorical(y, len(outputchar2idx))\n",
        "\n",
        "print(x.shape)\n",
        "print(x[:7])\n",
        "\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10887, 20, 65)\n",
            "[[[1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 1.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 1.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  [1. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]]\n",
            "(10887, 20, 65) (10887, 20, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaowjNiai96c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNqqnkVSwXC-"
      },
      "source": [
        "# Attention Mechanism\n",
        "## Task 2: Code your own (key-value) attention mechnism (1 point)\n",
        "* PLEASE READ: you DO NOT have to follow all the details in (Daniluk, et al. 2017). You just need to create a key-value attention mechanism where the \"key\" part of the mechanism is used for attention score calculation, and the \"value\" part of the mechanism is used to encode information to create a context vector.  \n",
        "* Define global variables\n",
        "* fill code for one_step_attention function\n",
        "* Hint: use keras.layers.Lambda \n",
        "* HINT: you will probably need more hidden dimmensions than what you've seen in the demo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSdFcuGuwXDB"
      },
      "source": [
        "from tensorflow.keras.activations import softmax\n",
        "from tensorflow.keras.layers import Lambda\n",
        "def softMaxAxis1(x):\n",
        "    return softmax(x,axis=1)\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS3Ziti1wXDH"
      },
      "source": [
        "#These are global variables (shared layers)\n",
        "## Fill your code here\n",
        "## you are allowed to use code in the demo as your template.\n",
        "from tensorflow import split\n",
        "\n",
        "repeator = RepeatVector(max_input)\n",
        "concatenator = Concatenate(axis=-1)\n",
        "splitter = Lambda(lambda tensor: split(tensor, num_or_size_splits=2, axis=-1) )\n",
        "\n",
        "fattn_1 = Dense(10, activation = \"tanh\")\n",
        "fattn_2 = Dense(1, activation = \"relu\")\n",
        "\n",
        "activator = Activation(softMaxAxis1, name='attention_scores') \n",
        "dotor = Dot(axes = 1)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecNci8x5wXDN"
      },
      "source": [
        "def one_step_attention(a, s_prev):\n",
        "\n",
        "    #Fill code here\n",
        "    a_k, a_v = splitter(a)\n",
        "    s_prev = repeator(s_prev)\n",
        "    concat = concatenator([a_k, s_prev])\n",
        "\n",
        "    e = fattn_1(concat)\n",
        "    en = fattn_2(e)\n",
        "\n",
        "    attention_scores = activator(en)\n",
        "    r = concatenator([a_v, s_prev])\n",
        "    re = fattn_1(r)\n",
        "\n",
        "    context =  dotor([attention_scores, re])\n",
        "    return context # return whatever you need to complete this homework "
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bgSCY3NwXDU"
      },
      "source": [
        "## Task3: Create and train your encoder/decoder model here (1 point)\n",
        "* HINT: you will probably need more hidden dimmensions than what you've seen in the demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CVrgh9nwXDV"
      },
      "source": [
        "#FILL CODE HERE\n",
        "n_h = 64 #hidden dimensions for encoder \n",
        "n_s = 64 #hidden dimensions for decoder\n",
        "m = 10887\n",
        "encoder_LSTM =  Bidirectional(LSTM(n_h, return_sequences=True),input_shape=(-1, max_input, n_h*2))\n",
        "decoder_LSTM_cell = LSTM(n_s, return_state = True) #decoder_LSTM_cell\n",
        "output_layer = Dense(output_vocab_size, activation=\"softmax\") #softmax output layer\n",
        "\n",
        "s0 = np.zeros((m, n_s))\n",
        "c0 = np.zeros((m, n_s))\n",
        "outputs = list(y.swapaxes(0,1))"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFd3lEfzn8_J",
        "outputId": "c12e9c68-958a-48f8-9699-8455bcba2f21"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "def model(Tx, Ty, n_h, n_s, input_vocab_size, output_vocab_size):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    Tx -- length of the input sequence\n",
        "    Ty -- length of the output sequence\n",
        "    n_h -- hidden state size of the Bi-LSTM\n",
        "    n_s -- hidden state size of the post-attention LSTM\n",
        "    input_vocab_size -- size of the input vocab\n",
        "    output_vocab_size -- size of the output vocab\n",
        "\n",
        "    Returns:\n",
        "    model -- Keras model instance\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input of your model\n",
        "    X = Input(shape=(Tx, len(inputchar2idx)))\n",
        "    # Define hidden state and cell state for decoder_LSTM_Cell\n",
        "    s0 = Input(shape=(n_s,), name='s0')\n",
        "    c0 = Input(shape=(n_s,), name='c0')\n",
        "    s = s0\n",
        "    c = c0\n",
        "    \n",
        "    # Initialize empty list of outputs\n",
        "    outputs = list()\n",
        "    #Encoder Bi-LSTM\n",
        "    # h = Bidirectional(LSTM(n_h, return_sequences=True),input_shape=(-1, Tx, n_h*2))(X)\n",
        "    h = encoder_LSTM(X)\n",
        "    #Iterate for Ty steps (Decoding)\n",
        "    for t in range(Ty):\n",
        "    \n",
        "        #Perform one step of the attention mechanism to calculate the context vector at timestep t\n",
        "        context = one_step_attention(h, s)\n",
        "       \n",
        "        # Feed the context vector to the decoder LSTM cell\n",
        "        s, _, c = decoder_LSTM_cell(context,initial_state=[s,c])\n",
        "           \n",
        "        # Pass the decoder hidden output to the output layer (softmax)\n",
        "        out = output_layer(s)\n",
        "        \n",
        "        # Append an output list with the current output\n",
        "        outputs.append(out)\n",
        "    \n",
        "    #Create model instance\n",
        "    model = Model(inputs=[X,s0,c0],outputs=outputs)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "model = model(max_input, max_output, n_h, n_s, len(inputchar2idx), len(outputchar2idx))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 20, 65)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 20, 128)      66560       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "s0 (InputLayer)                 [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 [(None, 20, 64), (No 0           bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector (RepeatVector)    (None, 20, 64)       0           s0[0][0]                         \n",
            "                                                                 lstm_1[0][0]                     \n",
            "                                                                 lstm_1[1][0]                     \n",
            "                                                                 lstm_1[2][0]                     \n",
            "                                                                 lstm_1[3][0]                     \n",
            "                                                                 lstm_1[4][0]                     \n",
            "                                                                 lstm_1[5][0]                     \n",
            "                                                                 lstm_1[6][0]                     \n",
            "                                                                 lstm_1[7][0]                     \n",
            "                                                                 lstm_1[8][0]                     \n",
            "                                                                 lstm_1[9][0]                     \n",
            "                                                                 lstm_1[10][0]                    \n",
            "                                                                 lstm_1[11][0]                    \n",
            "                                                                 lstm_1[12][0]                    \n",
            "                                                                 lstm_1[13][0]                    \n",
            "                                                                 lstm_1[14][0]                    \n",
            "                                                                 lstm_1[15][0]                    \n",
            "                                                                 lstm_1[16][0]                    \n",
            "                                                                 lstm_1[17][0]                    \n",
            "                                                                 lstm_1[18][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 20, 128)      0           lambda[0][0]                     \n",
            "                                                                 repeat_vector[0][0]              \n",
            "                                                                 lambda[0][1]                     \n",
            "                                                                 repeat_vector[0][0]              \n",
            "                                                                 lambda[1][0]                     \n",
            "                                                                 repeat_vector[1][0]              \n",
            "                                                                 lambda[1][1]                     \n",
            "                                                                 repeat_vector[1][0]              \n",
            "                                                                 lambda[2][0]                     \n",
            "                                                                 repeat_vector[2][0]              \n",
            "                                                                 lambda[2][1]                     \n",
            "                                                                 repeat_vector[2][0]              \n",
            "                                                                 lambda[3][0]                     \n",
            "                                                                 repeat_vector[3][0]              \n",
            "                                                                 lambda[3][1]                     \n",
            "                                                                 repeat_vector[3][0]              \n",
            "                                                                 lambda[4][0]                     \n",
            "                                                                 repeat_vector[4][0]              \n",
            "                                                                 lambda[4][1]                     \n",
            "                                                                 repeat_vector[4][0]              \n",
            "                                                                 lambda[5][0]                     \n",
            "                                                                 repeat_vector[5][0]              \n",
            "                                                                 lambda[5][1]                     \n",
            "                                                                 repeat_vector[5][0]              \n",
            "                                                                 lambda[6][0]                     \n",
            "                                                                 repeat_vector[6][0]              \n",
            "                                                                 lambda[6][1]                     \n",
            "                                                                 repeat_vector[6][0]              \n",
            "                                                                 lambda[7][0]                     \n",
            "                                                                 repeat_vector[7][0]              \n",
            "                                                                 lambda[7][1]                     \n",
            "                                                                 repeat_vector[7][0]              \n",
            "                                                                 lambda[8][0]                     \n",
            "                                                                 repeat_vector[8][0]              \n",
            "                                                                 lambda[8][1]                     \n",
            "                                                                 repeat_vector[8][0]              \n",
            "                                                                 lambda[9][0]                     \n",
            "                                                                 repeat_vector[9][0]              \n",
            "                                                                 lambda[9][1]                     \n",
            "                                                                 repeat_vector[9][0]              \n",
            "                                                                 lambda[10][0]                    \n",
            "                                                                 repeat_vector[10][0]             \n",
            "                                                                 lambda[10][1]                    \n",
            "                                                                 repeat_vector[10][0]             \n",
            "                                                                 lambda[11][0]                    \n",
            "                                                                 repeat_vector[11][0]             \n",
            "                                                                 lambda[11][1]                    \n",
            "                                                                 repeat_vector[11][0]             \n",
            "                                                                 lambda[12][0]                    \n",
            "                                                                 repeat_vector[12][0]             \n",
            "                                                                 lambda[12][1]                    \n",
            "                                                                 repeat_vector[12][0]             \n",
            "                                                                 lambda[13][0]                    \n",
            "                                                                 repeat_vector[13][0]             \n",
            "                                                                 lambda[13][1]                    \n",
            "                                                                 repeat_vector[13][0]             \n",
            "                                                                 lambda[14][0]                    \n",
            "                                                                 repeat_vector[14][0]             \n",
            "                                                                 lambda[14][1]                    \n",
            "                                                                 repeat_vector[14][0]             \n",
            "                                                                 lambda[15][0]                    \n",
            "                                                                 repeat_vector[15][0]             \n",
            "                                                                 lambda[15][1]                    \n",
            "                                                                 repeat_vector[15][0]             \n",
            "                                                                 lambda[16][0]                    \n",
            "                                                                 repeat_vector[16][0]             \n",
            "                                                                 lambda[16][1]                    \n",
            "                                                                 repeat_vector[16][0]             \n",
            "                                                                 lambda[17][0]                    \n",
            "                                                                 repeat_vector[17][0]             \n",
            "                                                                 lambda[17][1]                    \n",
            "                                                                 repeat_vector[17][0]             \n",
            "                                                                 lambda[18][0]                    \n",
            "                                                                 repeat_vector[18][0]             \n",
            "                                                                 lambda[18][1]                    \n",
            "                                                                 repeat_vector[18][0]             \n",
            "                                                                 lambda[19][0]                    \n",
            "                                                                 repeat_vector[19][0]             \n",
            "                                                                 lambda[19][1]                    \n",
            "                                                                 repeat_vector[19][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20, 10)       1290        concatenate[0][0]                \n",
            "                                                                 concatenate[1][0]                \n",
            "                                                                 concatenate[2][0]                \n",
            "                                                                 concatenate[3][0]                \n",
            "                                                                 concatenate[4][0]                \n",
            "                                                                 concatenate[5][0]                \n",
            "                                                                 concatenate[6][0]                \n",
            "                                                                 concatenate[7][0]                \n",
            "                                                                 concatenate[8][0]                \n",
            "                                                                 concatenate[9][0]                \n",
            "                                                                 concatenate[10][0]               \n",
            "                                                                 concatenate[11][0]               \n",
            "                                                                 concatenate[12][0]               \n",
            "                                                                 concatenate[13][0]               \n",
            "                                                                 concatenate[14][0]               \n",
            "                                                                 concatenate[15][0]               \n",
            "                                                                 concatenate[16][0]               \n",
            "                                                                 concatenate[17][0]               \n",
            "                                                                 concatenate[18][0]               \n",
            "                                                                 concatenate[19][0]               \n",
            "                                                                 concatenate[20][0]               \n",
            "                                                                 concatenate[21][0]               \n",
            "                                                                 concatenate[22][0]               \n",
            "                                                                 concatenate[23][0]               \n",
            "                                                                 concatenate[24][0]               \n",
            "                                                                 concatenate[25][0]               \n",
            "                                                                 concatenate[26][0]               \n",
            "                                                                 concatenate[27][0]               \n",
            "                                                                 concatenate[28][0]               \n",
            "                                                                 concatenate[29][0]               \n",
            "                                                                 concatenate[30][0]               \n",
            "                                                                 concatenate[31][0]               \n",
            "                                                                 concatenate[32][0]               \n",
            "                                                                 concatenate[33][0]               \n",
            "                                                                 concatenate[34][0]               \n",
            "                                                                 concatenate[35][0]               \n",
            "                                                                 concatenate[36][0]               \n",
            "                                                                 concatenate[37][0]               \n",
            "                                                                 concatenate[38][0]               \n",
            "                                                                 concatenate[39][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20, 1)        11          dense[0][0]                      \n",
            "                                                                 dense[2][0]                      \n",
            "                                                                 dense[4][0]                      \n",
            "                                                                 dense[6][0]                      \n",
            "                                                                 dense[8][0]                      \n",
            "                                                                 dense[10][0]                     \n",
            "                                                                 dense[12][0]                     \n",
            "                                                                 dense[14][0]                     \n",
            "                                                                 dense[16][0]                     \n",
            "                                                                 dense[18][0]                     \n",
            "                                                                 dense[20][0]                     \n",
            "                                                                 dense[22][0]                     \n",
            "                                                                 dense[24][0]                     \n",
            "                                                                 dense[26][0]                     \n",
            "                                                                 dense[28][0]                     \n",
            "                                                                 dense[30][0]                     \n",
            "                                                                 dense[32][0]                     \n",
            "                                                                 dense[34][0]                     \n",
            "                                                                 dense[36][0]                     \n",
            "                                                                 dense[38][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_scores (Activation)   (None, 20, 1)        0           dense_1[0][0]                    \n",
            "                                                                 dense_1[1][0]                    \n",
            "                                                                 dense_1[2][0]                    \n",
            "                                                                 dense_1[3][0]                    \n",
            "                                                                 dense_1[4][0]                    \n",
            "                                                                 dense_1[5][0]                    \n",
            "                                                                 dense_1[6][0]                    \n",
            "                                                                 dense_1[7][0]                    \n",
            "                                                                 dense_1[8][0]                    \n",
            "                                                                 dense_1[9][0]                    \n",
            "                                                                 dense_1[10][0]                   \n",
            "                                                                 dense_1[11][0]                   \n",
            "                                                                 dense_1[12][0]                   \n",
            "                                                                 dense_1[13][0]                   \n",
            "                                                                 dense_1[14][0]                   \n",
            "                                                                 dense_1[15][0]                   \n",
            "                                                                 dense_1[16][0]                   \n",
            "                                                                 dense_1[17][0]                   \n",
            "                                                                 dense_1[18][0]                   \n",
            "                                                                 dense_1[19][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 1, 10)        0           attention_scores[0][0]           \n",
            "                                                                 dense[1][0]                      \n",
            "                                                                 attention_scores[1][0]           \n",
            "                                                                 dense[3][0]                      \n",
            "                                                                 attention_scores[2][0]           \n",
            "                                                                 dense[5][0]                      \n",
            "                                                                 attention_scores[3][0]           \n",
            "                                                                 dense[7][0]                      \n",
            "                                                                 attention_scores[4][0]           \n",
            "                                                                 dense[9][0]                      \n",
            "                                                                 attention_scores[5][0]           \n",
            "                                                                 dense[11][0]                     \n",
            "                                                                 attention_scores[6][0]           \n",
            "                                                                 dense[13][0]                     \n",
            "                                                                 attention_scores[7][0]           \n",
            "                                                                 dense[15][0]                     \n",
            "                                                                 attention_scores[8][0]           \n",
            "                                                                 dense[17][0]                     \n",
            "                                                                 attention_scores[9][0]           \n",
            "                                                                 dense[19][0]                     \n",
            "                                                                 attention_scores[10][0]          \n",
            "                                                                 dense[21][0]                     \n",
            "                                                                 attention_scores[11][0]          \n",
            "                                                                 dense[23][0]                     \n",
            "                                                                 attention_scores[12][0]          \n",
            "                                                                 dense[25][0]                     \n",
            "                                                                 attention_scores[13][0]          \n",
            "                                                                 dense[27][0]                     \n",
            "                                                                 attention_scores[14][0]          \n",
            "                                                                 dense[29][0]                     \n",
            "                                                                 attention_scores[15][0]          \n",
            "                                                                 dense[31][0]                     \n",
            "                                                                 attention_scores[16][0]          \n",
            "                                                                 dense[33][0]                     \n",
            "                                                                 attention_scores[17][0]          \n",
            "                                                                 dense[35][0]                     \n",
            "                                                                 attention_scores[18][0]          \n",
            "                                                                 dense[37][0]                     \n",
            "                                                                 attention_scores[19][0]          \n",
            "                                                                 dense[39][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "c0 (InputLayer)                 [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 64), (None,  19200       dot[0][0]                        \n",
            "                                                                 s0[0][0]                         \n",
            "                                                                 c0[0][0]                         \n",
            "                                                                 dot[1][0]                        \n",
            "                                                                 lstm_1[0][0]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "                                                                 dot[2][0]                        \n",
            "                                                                 lstm_1[1][0]                     \n",
            "                                                                 lstm_1[1][2]                     \n",
            "                                                                 dot[3][0]                        \n",
            "                                                                 lstm_1[2][0]                     \n",
            "                                                                 lstm_1[2][2]                     \n",
            "                                                                 dot[4][0]                        \n",
            "                                                                 lstm_1[3][0]                     \n",
            "                                                                 lstm_1[3][2]                     \n",
            "                                                                 dot[5][0]                        \n",
            "                                                                 lstm_1[4][0]                     \n",
            "                                                                 lstm_1[4][2]                     \n",
            "                                                                 dot[6][0]                        \n",
            "                                                                 lstm_1[5][0]                     \n",
            "                                                                 lstm_1[5][2]                     \n",
            "                                                                 dot[7][0]                        \n",
            "                                                                 lstm_1[6][0]                     \n",
            "                                                                 lstm_1[6][2]                     \n",
            "                                                                 dot[8][0]                        \n",
            "                                                                 lstm_1[7][0]                     \n",
            "                                                                 lstm_1[7][2]                     \n",
            "                                                                 dot[9][0]                        \n",
            "                                                                 lstm_1[8][0]                     \n",
            "                                                                 lstm_1[8][2]                     \n",
            "                                                                 dot[10][0]                       \n",
            "                                                                 lstm_1[9][0]                     \n",
            "                                                                 lstm_1[9][2]                     \n",
            "                                                                 dot[11][0]                       \n",
            "                                                                 lstm_1[10][0]                    \n",
            "                                                                 lstm_1[10][2]                    \n",
            "                                                                 dot[12][0]                       \n",
            "                                                                 lstm_1[11][0]                    \n",
            "                                                                 lstm_1[11][2]                    \n",
            "                                                                 dot[13][0]                       \n",
            "                                                                 lstm_1[12][0]                    \n",
            "                                                                 lstm_1[12][2]                    \n",
            "                                                                 dot[14][0]                       \n",
            "                                                                 lstm_1[13][0]                    \n",
            "                                                                 lstm_1[13][2]                    \n",
            "                                                                 dot[15][0]                       \n",
            "                                                                 lstm_1[14][0]                    \n",
            "                                                                 lstm_1[14][2]                    \n",
            "                                                                 dot[16][0]                       \n",
            "                                                                 lstm_1[15][0]                    \n",
            "                                                                 lstm_1[15][2]                    \n",
            "                                                                 dot[17][0]                       \n",
            "                                                                 lstm_1[16][0]                    \n",
            "                                                                 lstm_1[16][2]                    \n",
            "                                                                 dot[18][0]                       \n",
            "                                                                 lstm_1[17][0]                    \n",
            "                                                                 lstm_1[17][2]                    \n",
            "                                                                 dot[19][0]                       \n",
            "                                                                 lstm_1[18][0]                    \n",
            "                                                                 lstm_1[18][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 24)           1560        lstm_1[0][0]                     \n",
            "                                                                 lstm_1[1][0]                     \n",
            "                                                                 lstm_1[2][0]                     \n",
            "                                                                 lstm_1[3][0]                     \n",
            "                                                                 lstm_1[4][0]                     \n",
            "                                                                 lstm_1[5][0]                     \n",
            "                                                                 lstm_1[6][0]                     \n",
            "                                                                 lstm_1[7][0]                     \n",
            "                                                                 lstm_1[8][0]                     \n",
            "                                                                 lstm_1[9][0]                     \n",
            "                                                                 lstm_1[10][0]                    \n",
            "                                                                 lstm_1[11][0]                    \n",
            "                                                                 lstm_1[12][0]                    \n",
            "                                                                 lstm_1[13][0]                    \n",
            "                                                                 lstm_1[14][0]                    \n",
            "                                                                 lstm_1[15][0]                    \n",
            "                                                                 lstm_1[16][0]                    \n",
            "                                                                 lstm_1[17][0]                    \n",
            "                                                                 lstm_1[18][0]                    \n",
            "                                                                 lstm_1[19][0]                    \n",
            "==================================================================================================\n",
            "Total params: 88,621\n",
            "Trainable params: 88,621\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XptuOQj-wXDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d938a53-85f9-4c41-e5db-1e61babde91f"
      },
      "source": [
        "#FIT YOUR MODEL HERE\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr= 0.01, clipvalue=0.5),metrics=['accuracy'])\n",
        "model.fit([x, s0, c0], outputs, epochs=35, batch_size=64)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "171/171 [==============================] - 60s 109ms/step - loss: 30.9055 - dense_2_loss: 0.6845 - dense_2_1_loss: 0.4579 - dense_2_2_loss: 0.3964 - dense_2_3_loss: 0.3774 - dense_2_4_loss: 0.3793 - dense_2_5_loss: 0.3941 - dense_2_6_loss: 0.4324 - dense_2_7_loss: 0.5015 - dense_2_8_loss: 0.6100 - dense_2_9_loss: 0.7774 - dense_2_10_loss: 1.0709 - dense_2_11_loss: 1.4603 - dense_2_12_loss: 1.9663 - dense_2_13_loss: 2.5730 - dense_2_14_loss: 2.9883 - dense_2_15_loss: 3.2146 - dense_2_16_loss: 3.2045 - dense_2_17_loss: 3.3885 - dense_2_18_loss: 3.0505 - dense_2_19_loss: 2.9777 - dense_2_accuracy: 0.9943 - dense_2_1_accuracy: 0.9941 - dense_2_2_accuracy: 0.9935 - dense_2_3_accuracy: 0.9922 - dense_2_4_accuracy: 0.9893 - dense_2_5_accuracy: 0.9850 - dense_2_6_accuracy: 0.9776 - dense_2_7_accuracy: 0.9651 - dense_2_8_accuracy: 0.9430 - dense_2_9_accuracy: 0.9085 - dense_2_10_accuracy: 0.8315 - dense_2_11_accuracy: 0.7204 - dense_2_12_accuracy: 0.5615 - dense_2_13_accuracy: 0.3561 - dense_2_14_accuracy: 0.1861 - dense_2_15_accuracy: 0.0999 - dense_2_16_accuracy: 0.0934 - dense_2_17_accuracy: 0.0278 - dense_2_18_accuracy: 0.1296 - dense_2_19_accuracy: 0.0605\n",
            "Epoch 2/35\n",
            "171/171 [==============================] - 19s 109ms/step - loss: 21.3434 - dense_2_loss: 0.0146 - dense_2_1_loss: 8.5020e-04 - dense_2_2_loss: 0.0017 - dense_2_3_loss: 0.0058 - dense_2_4_loss: 0.0105 - dense_2_5_loss: 0.0158 - dense_2_6_loss: 0.0454 - dense_2_7_loss: 0.0854 - dense_2_8_loss: 0.1718 - dense_2_9_loss: 0.3218 - dense_2_10_loss: 0.5597 - dense_2_11_loss: 0.9429 - dense_2_12_loss: 1.4876 - dense_2_13_loss: 2.0508 - dense_2_14_loss: 2.4926 - dense_2_15_loss: 2.6810 - dense_2_16_loss: 2.6939 - dense_2_17_loss: 2.9294 - dense_2_18_loss: 2.5182 - dense_2_19_loss: 2.3137 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9991 - dense_2_4_accuracy: 0.9984 - dense_2_5_accuracy: 0.9975 - dense_2_6_accuracy: 0.9923 - dense_2_7_accuracy: 0.9840 - dense_2_8_accuracy: 0.9668 - dense_2_9_accuracy: 0.9340 - dense_2_10_accuracy: 0.8737 - dense_2_11_accuracy: 0.7687 - dense_2_12_accuracy: 0.6093 - dense_2_13_accuracy: 0.4260 - dense_2_14_accuracy: 0.2652 - dense_2_15_accuracy: 0.1992 - dense_2_16_accuracy: 0.2135 - dense_2_17_accuracy: 0.0676 - dense_2_18_accuracy: 0.2983 - dense_2_19_accuracy: 0.1750\n",
            "Epoch 3/35\n",
            "171/171 [==============================] - 19s 109ms/step - loss: 20.3864 - dense_2_loss: 0.0034 - dense_2_1_loss: 7.6528e-04 - dense_2_2_loss: 8.5536e-04 - dense_2_3_loss: 0.0074 - dense_2_4_loss: 0.0116 - dense_2_5_loss: 0.0167 - dense_2_6_loss: 0.0375 - dense_2_7_loss: 0.0770 - dense_2_8_loss: 0.1498 - dense_2_9_loss: 0.2843 - dense_2_10_loss: 0.5122 - dense_2_11_loss: 0.8525 - dense_2_12_loss: 1.3742 - dense_2_13_loss: 1.9447 - dense_2_14_loss: 2.3532 - dense_2_15_loss: 2.5974 - dense_2_16_loss: 2.6325 - dense_2_17_loss: 2.8790 - dense_2_18_loss: 2.4787 - dense_2_19_loss: 2.1726 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9991 - dense_2_4_accuracy: 0.9982 - dense_2_5_accuracy: 0.9970 - dense_2_6_accuracy: 0.9931 - dense_2_7_accuracy: 0.9853 - dense_2_8_accuracy: 0.9675 - dense_2_9_accuracy: 0.9369 - dense_2_10_accuracy: 0.8705 - dense_2_11_accuracy: 0.7725 - dense_2_12_accuracy: 0.6274 - dense_2_13_accuracy: 0.4321 - dense_2_14_accuracy: 0.2945 - dense_2_15_accuracy: 0.2072 - dense_2_16_accuracy: 0.2231 - dense_2_17_accuracy: 0.0746 - dense_2_18_accuracy: 0.2882 - dense_2_19_accuracy: 0.2330\n",
            "Epoch 4/35\n",
            "171/171 [==============================] - 19s 110ms/step - loss: 19.6257 - dense_2_loss: 0.0037 - dense_2_1_loss: 9.3795e-04 - dense_2_2_loss: 0.0023 - dense_2_3_loss: 0.0045 - dense_2_4_loss: 0.0082 - dense_2_5_loss: 0.0149 - dense_2_6_loss: 0.0364 - dense_2_7_loss: 0.0710 - dense_2_8_loss: 0.1398 - dense_2_9_loss: 0.2562 - dense_2_10_loss: 0.4823 - dense_2_11_loss: 0.8121 - dense_2_12_loss: 1.2854 - dense_2_13_loss: 1.8471 - dense_2_14_loss: 2.3005 - dense_2_15_loss: 2.5501 - dense_2_16_loss: 2.5759 - dense_2_17_loss: 2.7650 - dense_2_18_loss: 2.3941 - dense_2_19_loss: 2.0752 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9990 - dense_2_4_accuracy: 0.9982 - dense_2_5_accuracy: 0.9968 - dense_2_6_accuracy: 0.9921 - dense_2_7_accuracy: 0.9841 - dense_2_8_accuracy: 0.9657 - dense_2_9_accuracy: 0.9373 - dense_2_10_accuracy: 0.8737 - dense_2_11_accuracy: 0.7799 - dense_2_12_accuracy: 0.6325 - dense_2_13_accuracy: 0.4486 - dense_2_14_accuracy: 0.2851 - dense_2_15_accuracy: 0.1997 - dense_2_16_accuracy: 0.2096 - dense_2_17_accuracy: 0.1255 - dense_2_18_accuracy: 0.3210 - dense_2_19_accuracy: 0.2498\n",
            "Epoch 5/35\n",
            "171/171 [==============================] - 19s 109ms/step - loss: 18.9666 - dense_2_loss: 0.0034 - dense_2_1_loss: 8.9537e-04 - dense_2_2_loss: 0.0014 - dense_2_3_loss: 0.0053 - dense_2_4_loss: 0.0090 - dense_2_5_loss: 0.0148 - dense_2_6_loss: 0.0295 - dense_2_7_loss: 0.0594 - dense_2_8_loss: 0.1212 - dense_2_9_loss: 0.2374 - dense_2_10_loss: 0.4640 - dense_2_11_loss: 0.8057 - dense_2_12_loss: 1.2498 - dense_2_13_loss: 1.7817 - dense_2_14_loss: 2.2608 - dense_2_15_loss: 2.5211 - dense_2_16_loss: 2.5162 - dense_2_17_loss: 2.6445 - dense_2_18_loss: 2.2790 - dense_2_19_loss: 1.9615 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9990 - dense_2_4_accuracy: 0.9980 - dense_2_5_accuracy: 0.9965 - dense_2_6_accuracy: 0.9931 - dense_2_7_accuracy: 0.9868 - dense_2_8_accuracy: 0.9697 - dense_2_9_accuracy: 0.9419 - dense_2_10_accuracy: 0.8751 - dense_2_11_accuracy: 0.7783 - dense_2_12_accuracy: 0.6446 - dense_2_13_accuracy: 0.4695 - dense_2_14_accuracy: 0.2959 - dense_2_15_accuracy: 0.2036 - dense_2_16_accuracy: 0.2002 - dense_2_17_accuracy: 0.1723 - dense_2_18_accuracy: 0.3431 - dense_2_19_accuracy: 0.2991\n",
            "Epoch 6/35\n",
            "171/171 [==============================] - 19s 112ms/step - loss: 18.7020 - dense_2_loss: 0.0034 - dense_2_1_loss: 6.2519e-04 - dense_2_2_loss: 5.5010e-04 - dense_2_3_loss: 0.0053 - dense_2_4_loss: 0.0101 - dense_2_5_loss: 0.0162 - dense_2_6_loss: 0.0386 - dense_2_7_loss: 0.0736 - dense_2_8_loss: 0.1292 - dense_2_9_loss: 0.2447 - dense_2_10_loss: 0.4594 - dense_2_11_loss: 0.7742 - dense_2_12_loss: 1.2447 - dense_2_13_loss: 1.7918 - dense_2_14_loss: 2.2507 - dense_2_15_loss: 2.4783 - dense_2_16_loss: 2.4594 - dense_2_17_loss: 2.6187 - dense_2_18_loss: 2.1860 - dense_2_19_loss: 1.9165 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9989 - dense_2_4_accuracy: 0.9978 - dense_2_5_accuracy: 0.9955 - dense_2_6_accuracy: 0.9904 - dense_2_7_accuracy: 0.9820 - dense_2_8_accuracy: 0.9667 - dense_2_9_accuracy: 0.9386 - dense_2_10_accuracy: 0.8757 - dense_2_11_accuracy: 0.7848 - dense_2_12_accuracy: 0.6354 - dense_2_13_accuracy: 0.4610 - dense_2_14_accuracy: 0.2953 - dense_2_15_accuracy: 0.2060 - dense_2_16_accuracy: 0.1993 - dense_2_17_accuracy: 0.1882 - dense_2_18_accuracy: 0.3434 - dense_2_19_accuracy: 0.3412\n",
            "Epoch 7/35\n",
            "171/171 [==============================] - 19s 112ms/step - loss: 17.2173 - dense_2_loss: 0.0027 - dense_2_1_loss: 0.0016 - dense_2_2_loss: 0.0015 - dense_2_3_loss: 0.0030 - dense_2_4_loss: 0.0056 - dense_2_5_loss: 0.0123 - dense_2_6_loss: 0.0289 - dense_2_7_loss: 0.0532 - dense_2_8_loss: 0.1105 - dense_2_9_loss: 0.2268 - dense_2_10_loss: 0.4220 - dense_2_11_loss: 0.7265 - dense_2_12_loss: 1.1599 - dense_2_13_loss: 1.6576 - dense_2_14_loss: 2.0890 - dense_2_15_loss: 2.3556 - dense_2_16_loss: 2.3343 - dense_2_17_loss: 2.4408 - dense_2_18_loss: 1.9569 - dense_2_19_loss: 1.6286 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9997 - dense_2_2_accuracy: 0.9996 - dense_2_3_accuracy: 0.9993 - dense_2_4_accuracy: 0.9987 - dense_2_5_accuracy: 0.9973 - dense_2_6_accuracy: 0.9924 - dense_2_7_accuracy: 0.9862 - dense_2_8_accuracy: 0.9703 - dense_2_9_accuracy: 0.9414 - dense_2_10_accuracy: 0.8808 - dense_2_11_accuracy: 0.7924 - dense_2_12_accuracy: 0.6508 - dense_2_13_accuracy: 0.4781 - dense_2_14_accuracy: 0.3279 - dense_2_15_accuracy: 0.2387 - dense_2_16_accuracy: 0.2266 - dense_2_17_accuracy: 0.2449 - dense_2_18_accuracy: 0.4033 - dense_2_19_accuracy: 0.4466\n",
            "Epoch 8/35\n",
            "171/171 [==============================] - 19s 111ms/step - loss: 16.1291 - dense_2_loss: 0.0040 - dense_2_1_loss: 8.7272e-04 - dense_2_2_loss: 0.0018 - dense_2_3_loss: 0.0038 - dense_2_4_loss: 0.0088 - dense_2_5_loss: 0.0153 - dense_2_6_loss: 0.0280 - dense_2_7_loss: 0.0592 - dense_2_8_loss: 0.1119 - dense_2_9_loss: 0.2002 - dense_2_10_loss: 0.3904 - dense_2_11_loss: 0.6756 - dense_2_12_loss: 1.0860 - dense_2_13_loss: 1.5746 - dense_2_14_loss: 2.0108 - dense_2_15_loss: 2.2497 - dense_2_16_loss: 2.2251 - dense_2_17_loss: 2.2280 - dense_2_18_loss: 1.7994 - dense_2_19_loss: 1.4556 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9994 - dense_2_3_accuracy: 0.9991 - dense_2_4_accuracy: 0.9978 - dense_2_5_accuracy: 0.9968 - dense_2_6_accuracy: 0.9930 - dense_2_7_accuracy: 0.9849 - dense_2_8_accuracy: 0.9692 - dense_2_9_accuracy: 0.9455 - dense_2_10_accuracy: 0.8863 - dense_2_11_accuracy: 0.8017 - dense_2_12_accuracy: 0.6691 - dense_2_13_accuracy: 0.5038 - dense_2_14_accuracy: 0.3446 - dense_2_15_accuracy: 0.2700 - dense_2_16_accuracy: 0.2550 - dense_2_17_accuracy: 0.3440 - dense_2_18_accuracy: 0.4437 - dense_2_19_accuracy: 0.4866\n",
            "Epoch 9/35\n",
            "171/171 [==============================] - 19s 112ms/step - loss: 15.7411 - dense_2_loss: 0.0052 - dense_2_1_loss: 0.0022 - dense_2_2_loss: 0.0026 - dense_2_3_loss: 0.0069 - dense_2_4_loss: 0.0102 - dense_2_5_loss: 0.0149 - dense_2_6_loss: 0.0246 - dense_2_7_loss: 0.0500 - dense_2_8_loss: 0.1177 - dense_2_9_loss: 0.2223 - dense_2_10_loss: 0.3980 - dense_2_11_loss: 0.6758 - dense_2_12_loss: 1.0834 - dense_2_13_loss: 1.5750 - dense_2_14_loss: 1.9964 - dense_2_15_loss: 2.2048 - dense_2_16_loss: 2.1406 - dense_2_17_loss: 2.1521 - dense_2_18_loss: 1.7364 - dense_2_19_loss: 1.3220 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9997 - dense_2_2_accuracy: 0.9996 - dense_2_3_accuracy: 0.9983 - dense_2_4_accuracy: 0.9978 - dense_2_5_accuracy: 0.9965 - dense_2_6_accuracy: 0.9933 - dense_2_7_accuracy: 0.9869 - dense_2_8_accuracy: 0.9672 - dense_2_9_accuracy: 0.9361 - dense_2_10_accuracy: 0.8846 - dense_2_11_accuracy: 0.7981 - dense_2_12_accuracy: 0.6688 - dense_2_13_accuracy: 0.5019 - dense_2_14_accuracy: 0.3646 - dense_2_15_accuracy: 0.2702 - dense_2_16_accuracy: 0.2911 - dense_2_17_accuracy: 0.3451 - dense_2_18_accuracy: 0.4559 - dense_2_19_accuracy: 0.5302\n",
            "Epoch 10/35\n",
            "171/171 [==============================] - 19s 113ms/step - loss: 14.2018 - dense_2_loss: 0.0028 - dense_2_1_loss: 5.8635e-04 - dense_2_2_loss: 0.0016 - dense_2_3_loss: 0.0043 - dense_2_4_loss: 0.0108 - dense_2_5_loss: 0.0147 - dense_2_6_loss: 0.0289 - dense_2_7_loss: 0.0533 - dense_2_8_loss: 0.1062 - dense_2_9_loss: 0.2059 - dense_2_10_loss: 0.3664 - dense_2_11_loss: 0.6423 - dense_2_12_loss: 1.0319 - dense_2_13_loss: 1.4565 - dense_2_14_loss: 1.8617 - dense_2_15_loss: 2.0829 - dense_2_16_loss: 1.9065 - dense_2_17_loss: 1.9051 - dense_2_18_loss: 1.4805 - dense_2_19_loss: 1.0388 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9991 - dense_2_4_accuracy: 0.9979 - dense_2_5_accuracy: 0.9969 - dense_2_6_accuracy: 0.9926 - dense_2_7_accuracy: 0.9863 - dense_2_8_accuracy: 0.9708 - dense_2_9_accuracy: 0.9430 - dense_2_10_accuracy: 0.8903 - dense_2_11_accuracy: 0.8094 - dense_2_12_accuracy: 0.6884 - dense_2_13_accuracy: 0.5483 - dense_2_14_accuracy: 0.4264 - dense_2_15_accuracy: 0.3129 - dense_2_16_accuracy: 0.3875 - dense_2_17_accuracy: 0.4190 - dense_2_18_accuracy: 0.5339 - dense_2_19_accuracy: 0.6658\n",
            "Epoch 11/35\n",
            "171/171 [==============================] - 19s 113ms/step - loss: 13.0010 - dense_2_loss: 0.0023 - dense_2_1_loss: 0.0020 - dense_2_2_loss: 0.0025 - dense_2_3_loss: 0.0117 - dense_2_4_loss: 0.0120 - dense_2_5_loss: 0.0141 - dense_2_6_loss: 0.0283 - dense_2_7_loss: 0.0589 - dense_2_8_loss: 0.1026 - dense_2_9_loss: 0.2044 - dense_2_10_loss: 0.3568 - dense_2_11_loss: 0.6068 - dense_2_12_loss: 0.9600 - dense_2_13_loss: 1.3700 - dense_2_14_loss: 1.7379 - dense_2_15_loss: 1.9113 - dense_2_16_loss: 1.7482 - dense_2_17_loss: 1.6711 - dense_2_18_loss: 1.3305 - dense_2_19_loss: 0.8695 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9996 - dense_2_3_accuracy: 0.9984 - dense_2_4_accuracy: 0.9976 - dense_2_5_accuracy: 0.9963 - dense_2_6_accuracy: 0.9931 - dense_2_7_accuracy: 0.9847 - dense_2_8_accuracy: 0.9714 - dense_2_9_accuracy: 0.9436 - dense_2_10_accuracy: 0.8923 - dense_2_11_accuracy: 0.8138 - dense_2_12_accuracy: 0.7044 - dense_2_13_accuracy: 0.5776 - dense_2_14_accuracy: 0.4594 - dense_2_15_accuracy: 0.3821 - dense_2_16_accuracy: 0.4527 - dense_2_17_accuracy: 0.5031 - dense_2_18_accuracy: 0.5602 - dense_2_19_accuracy: 0.7154\n",
            "Epoch 12/35\n",
            "171/171 [==============================] - 19s 112ms/step - loss: 12.3574 - dense_2_loss: 0.0021 - dense_2_1_loss: 5.1304e-04 - dense_2_2_loss: 0.0012 - dense_2_3_loss: 0.0037 - dense_2_4_loss: 0.0077 - dense_2_5_loss: 0.0096 - dense_2_6_loss: 0.0301 - dense_2_7_loss: 0.0585 - dense_2_8_loss: 0.0992 - dense_2_9_loss: 0.1914 - dense_2_10_loss: 0.3379 - dense_2_11_loss: 0.5862 - dense_2_12_loss: 0.9365 - dense_2_13_loss: 1.2986 - dense_2_14_loss: 1.6594 - dense_2_15_loss: 1.8123 - dense_2_16_loss: 1.6338 - dense_2_17_loss: 1.5795 - dense_2_18_loss: 1.2785 - dense_2_19_loss: 0.8308 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9992 - dense_2_4_accuracy: 0.9985 - dense_2_5_accuracy: 0.9977 - dense_2_6_accuracy: 0.9928 - dense_2_7_accuracy: 0.9844 - dense_2_8_accuracy: 0.9721 - dense_2_9_accuracy: 0.9454 - dense_2_10_accuracy: 0.8979 - dense_2_11_accuracy: 0.8229 - dense_2_12_accuracy: 0.7134 - dense_2_13_accuracy: 0.6011 - dense_2_14_accuracy: 0.4758 - dense_2_15_accuracy: 0.4268 - dense_2_16_accuracy: 0.4845 - dense_2_17_accuracy: 0.5180 - dense_2_18_accuracy: 0.5711 - dense_2_19_accuracy: 0.7286\n",
            "Epoch 13/35\n",
            "171/171 [==============================] - 19s 112ms/step - loss: 11.7884 - dense_2_loss: 0.0024 - dense_2_1_loss: 8.1541e-05 - dense_2_2_loss: 3.8136e-04 - dense_2_3_loss: 0.0023 - dense_2_4_loss: 0.0049 - dense_2_5_loss: 0.0097 - dense_2_6_loss: 0.0246 - dense_2_7_loss: 0.0440 - dense_2_8_loss: 0.0905 - dense_2_9_loss: 0.1802 - dense_2_10_loss: 0.3302 - dense_2_11_loss: 0.5730 - dense_2_12_loss: 0.9114 - dense_2_13_loss: 1.2561 - dense_2_14_loss: 1.5898 - dense_2_15_loss: 1.7340 - dense_2_16_loss: 1.5710 - dense_2_17_loss: 1.5076 - dense_2_18_loss: 1.1987 - dense_2_19_loss: 0.7573 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 0.9994 - dense_2_4_accuracy: 0.9987 - dense_2_5_accuracy: 0.9974 - dense_2_6_accuracy: 0.9936 - dense_2_7_accuracy: 0.9870 - dense_2_8_accuracy: 0.9735 - dense_2_9_accuracy: 0.9496 - dense_2_10_accuracy: 0.8985 - dense_2_11_accuracy: 0.8265 - dense_2_12_accuracy: 0.7195 - dense_2_13_accuracy: 0.6108 - dense_2_14_accuracy: 0.4996 - dense_2_15_accuracy: 0.4568 - dense_2_16_accuracy: 0.4983 - dense_2_17_accuracy: 0.5424 - dense_2_18_accuracy: 0.6104 - dense_2_19_accuracy: 0.7679\n",
            "Epoch 14/35\n",
            "171/171 [==============================] - 19s 112ms/step - loss: 10.6582 - dense_2_loss: 0.0019 - dense_2_1_loss: 4.8480e-04 - dense_2_2_loss: 8.6953e-04 - dense_2_3_loss: 0.0040 - dense_2_4_loss: 0.0066 - dense_2_5_loss: 0.0096 - dense_2_6_loss: 0.0254 - dense_2_7_loss: 0.0499 - dense_2_8_loss: 0.0889 - dense_2_9_loss: 0.1683 - dense_2_10_loss: 0.3067 - dense_2_11_loss: 0.5313 - dense_2_12_loss: 0.8377 - dense_2_13_loss: 1.1581 - dense_2_14_loss: 1.4691 - dense_2_15_loss: 1.5704 - dense_2_16_loss: 1.4323 - dense_2_17_loss: 1.3425 - dense_2_18_loss: 1.0209 - dense_2_19_loss: 0.6333 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9995 - dense_2_4_accuracy: 0.9985 - dense_2_5_accuracy: 0.9976 - dense_2_6_accuracy: 0.9938 - dense_2_7_accuracy: 0.9872 - dense_2_8_accuracy: 0.9755 - dense_2_9_accuracy: 0.9524 - dense_2_10_accuracy: 0.9093 - dense_2_11_accuracy: 0.8310 - dense_2_12_accuracy: 0.7377 - dense_2_13_accuracy: 0.6425 - dense_2_14_accuracy: 0.5433 - dense_2_15_accuracy: 0.5135 - dense_2_16_accuracy: 0.5475 - dense_2_17_accuracy: 0.5894 - dense_2_18_accuracy: 0.6678 - dense_2_19_accuracy: 0.8113\n",
            "Epoch 15/35\n",
            "171/171 [==============================] - 19s 112ms/step - loss: 10.2184 - dense_2_loss: 0.0012 - dense_2_1_loss: 0.0012 - dense_2_2_loss: 0.0022 - dense_2_3_loss: 0.0051 - dense_2_4_loss: 0.0070 - dense_2_5_loss: 0.0094 - dense_2_6_loss: 0.0244 - dense_2_7_loss: 0.0535 - dense_2_8_loss: 0.0914 - dense_2_9_loss: 0.1709 - dense_2_10_loss: 0.2958 - dense_2_11_loss: 0.5044 - dense_2_12_loss: 0.7868 - dense_2_13_loss: 1.1131 - dense_2_14_loss: 1.4112 - dense_2_15_loss: 1.5153 - dense_2_16_loss: 1.3935 - dense_2_17_loss: 1.2687 - dense_2_18_loss: 0.9638 - dense_2_19_loss: 0.5993 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9996 - dense_2_3_accuracy: 0.9990 - dense_2_4_accuracy: 0.9980 - dense_2_5_accuracy: 0.9975 - dense_2_6_accuracy: 0.9934 - dense_2_7_accuracy: 0.9851 - dense_2_8_accuracy: 0.9737 - dense_2_9_accuracy: 0.9485 - dense_2_10_accuracy: 0.9111 - dense_2_11_accuracy: 0.8462 - dense_2_12_accuracy: 0.7530 - dense_2_13_accuracy: 0.6616 - dense_2_14_accuracy: 0.5597 - dense_2_15_accuracy: 0.5390 - dense_2_16_accuracy: 0.5655 - dense_2_17_accuracy: 0.6017 - dense_2_18_accuracy: 0.7006 - dense_2_19_accuracy: 0.8176\n",
            "Epoch 16/35\n",
            "171/171 [==============================] - 19s 113ms/step - loss: 9.8488 - dense_2_loss: 0.0014 - dense_2_1_loss: 0.0012 - dense_2_2_loss: 0.0029 - dense_2_3_loss: 0.0047 - dense_2_4_loss: 0.0061 - dense_2_5_loss: 0.0131 - dense_2_6_loss: 0.0245 - dense_2_7_loss: 0.0480 - dense_2_8_loss: 0.0945 - dense_2_9_loss: 0.1684 - dense_2_10_loss: 0.2852 - dense_2_11_loss: 0.4928 - dense_2_12_loss: 0.7840 - dense_2_13_loss: 1.0611 - dense_2_14_loss: 1.3553 - dense_2_15_loss: 1.4420 - dense_2_16_loss: 1.3482 - dense_2_17_loss: 1.2345 - dense_2_18_loss: 0.9251 - dense_2_19_loss: 0.5557 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9994 - dense_2_3_accuracy: 0.9993 - dense_2_4_accuracy: 0.9983 - dense_2_5_accuracy: 0.9970 - dense_2_6_accuracy: 0.9939 - dense_2_7_accuracy: 0.9871 - dense_2_8_accuracy: 0.9751 - dense_2_9_accuracy: 0.9502 - dense_2_10_accuracy: 0.9135 - dense_2_11_accuracy: 0.8506 - dense_2_12_accuracy: 0.7571 - dense_2_13_accuracy: 0.6734 - dense_2_14_accuracy: 0.5846 - dense_2_15_accuracy: 0.5507 - dense_2_16_accuracy: 0.5725 - dense_2_17_accuracy: 0.6198 - dense_2_18_accuracy: 0.7163 - dense_2_19_accuracy: 0.8304\n",
            "Epoch 17/35\n",
            "171/171 [==============================] - 19s 113ms/step - loss: 9.4011 - dense_2_loss: 0.0016 - dense_2_1_loss: 8.3027e-04 - dense_2_2_loss: 0.0027 - dense_2_3_loss: 0.0051 - dense_2_4_loss: 0.0052 - dense_2_5_loss: 0.0098 - dense_2_6_loss: 0.0269 - dense_2_7_loss: 0.0436 - dense_2_8_loss: 0.0819 - dense_2_9_loss: 0.1516 - dense_2_10_loss: 0.2576 - dense_2_11_loss: 0.4755 - dense_2_12_loss: 0.7413 - dense_2_13_loss: 1.0102 - dense_2_14_loss: 1.3050 - dense_2_15_loss: 1.3959 - dense_2_16_loss: 1.3196 - dense_2_17_loss: 1.1788 - dense_2_18_loss: 0.8546 - dense_2_19_loss: 0.5337 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9996 - dense_2_3_accuracy: 0.9988 - dense_2_4_accuracy: 0.9987 - dense_2_5_accuracy: 0.9977 - dense_2_6_accuracy: 0.9931 - dense_2_7_accuracy: 0.9884 - dense_2_8_accuracy: 0.9768 - dense_2_9_accuracy: 0.9535 - dense_2_10_accuracy: 0.9221 - dense_2_11_accuracy: 0.8511 - dense_2_12_accuracy: 0.7699 - dense_2_13_accuracy: 0.6926 - dense_2_14_accuracy: 0.5959 - dense_2_15_accuracy: 0.5679 - dense_2_16_accuracy: 0.5790 - dense_2_17_accuracy: 0.6371 - dense_2_18_accuracy: 0.7395 - dense_2_19_accuracy: 0.8497\n",
            "Epoch 18/35\n",
            "171/171 [==============================] - 19s 112ms/step - loss: 8.6585 - dense_2_loss: 0.0013 - dense_2_1_loss: 0.0018 - dense_2_2_loss: 0.0013 - dense_2_3_loss: 0.0036 - dense_2_4_loss: 0.0060 - dense_2_5_loss: 0.0097 - dense_2_6_loss: 0.0180 - dense_2_7_loss: 0.0398 - dense_2_8_loss: 0.0759 - dense_2_9_loss: 0.1429 - dense_2_10_loss: 0.2535 - dense_2_11_loss: 0.4411 - dense_2_12_loss: 0.7043 - dense_2_13_loss: 0.9199 - dense_2_14_loss: 1.2011 - dense_2_15_loss: 1.3035 - dense_2_16_loss: 1.2201 - dense_2_17_loss: 1.0879 - dense_2_18_loss: 0.7516 - dense_2_19_loss: 0.4751 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9994 - dense_2_2_accuracy: 0.9993 - dense_2_3_accuracy: 0.9994 - dense_2_4_accuracy: 0.9983 - dense_2_5_accuracy: 0.9977 - dense_2_6_accuracy: 0.9954 - dense_2_7_accuracy: 0.9896 - dense_2_8_accuracy: 0.9787 - dense_2_9_accuracy: 0.9594 - dense_2_10_accuracy: 0.9228 - dense_2_11_accuracy: 0.8706 - dense_2_12_accuracy: 0.7852 - dense_2_13_accuracy: 0.7282 - dense_2_14_accuracy: 0.6433 - dense_2_15_accuracy: 0.6049 - dense_2_16_accuracy: 0.6173 - dense_2_17_accuracy: 0.6661 - dense_2_18_accuracy: 0.7730 - dense_2_19_accuracy: 0.8600\n",
            "Epoch 19/35\n",
            "171/171 [==============================] - 19s 112ms/step - loss: 8.0690 - dense_2_loss: 0.0011 - dense_2_1_loss: 9.3236e-04 - dense_2_2_loss: 9.9469e-04 - dense_2_3_loss: 0.0047 - dense_2_4_loss: 0.0055 - dense_2_5_loss: 0.0109 - dense_2_6_loss: 0.0206 - dense_2_7_loss: 0.0382 - dense_2_8_loss: 0.0736 - dense_2_9_loss: 0.1421 - dense_2_10_loss: 0.2411 - dense_2_11_loss: 0.4088 - dense_2_12_loss: 0.6510 - dense_2_13_loss: 0.8596 - dense_2_14_loss: 1.1221 - dense_2_15_loss: 1.2173 - dense_2_16_loss: 1.1559 - dense_2_17_loss: 1.0050 - dense_2_18_loss: 0.6718 - dense_2_19_loss: 0.4377 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9989 - dense_2_4_accuracy: 0.9988 - dense_2_5_accuracy: 0.9971 - dense_2_6_accuracy: 0.9936 - dense_2_7_accuracy: 0.9886 - dense_2_8_accuracy: 0.9781 - dense_2_9_accuracy: 0.9610 - dense_2_10_accuracy: 0.9271 - dense_2_11_accuracy: 0.8743 - dense_2_12_accuracy: 0.8045 - dense_2_13_accuracy: 0.7468 - dense_2_14_accuracy: 0.6592 - dense_2_15_accuracy: 0.6340 - dense_2_16_accuracy: 0.6390 - dense_2_17_accuracy: 0.6977 - dense_2_18_accuracy: 0.7984 - dense_2_19_accuracy: 0.8737\n",
            "Epoch 20/35\n",
            "171/171 [==============================] - 19s 112ms/step - loss: 7.9514 - dense_2_loss: 9.0035e-04 - dense_2_1_loss: 3.6411e-04 - dense_2_2_loss: 5.8706e-04 - dense_2_3_loss: 0.0035 - dense_2_4_loss: 0.0055 - dense_2_5_loss: 0.0112 - dense_2_6_loss: 0.0242 - dense_2_7_loss: 0.0488 - dense_2_8_loss: 0.0737 - dense_2_9_loss: 0.1423 - dense_2_10_loss: 0.2375 - dense_2_11_loss: 0.4238 - dense_2_12_loss: 0.6554 - dense_2_13_loss: 0.8607 - dense_2_14_loss: 1.1369 - dense_2_15_loss: 1.2216 - dense_2_16_loss: 1.1210 - dense_2_17_loss: 0.9675 - dense_2_18_loss: 0.6178 - dense_2_19_loss: 0.3983 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9992 - dense_2_4_accuracy: 0.9985 - dense_2_5_accuracy: 0.9973 - dense_2_6_accuracy: 0.9933 - dense_2_7_accuracy: 0.9866 - dense_2_8_accuracy: 0.9784 - dense_2_9_accuracy: 0.9590 - dense_2_10_accuracy: 0.9318 - dense_2_11_accuracy: 0.8707 - dense_2_12_accuracy: 0.8043 - dense_2_13_accuracy: 0.7410 - dense_2_14_accuracy: 0.6552 - dense_2_15_accuracy: 0.6319 - dense_2_16_accuracy: 0.6507 - dense_2_17_accuracy: 0.7076 - dense_2_18_accuracy: 0.8133 - dense_2_19_accuracy: 0.8789\n",
            "Epoch 21/35\n",
            "171/171 [==============================] - 19s 113ms/step - loss: 7.8421 - dense_2_loss: 9.2680e-04 - dense_2_1_loss: 3.2484e-04 - dense_2_2_loss: 8.8070e-04 - dense_2_3_loss: 0.0039 - dense_2_4_loss: 0.0064 - dense_2_5_loss: 0.0115 - dense_2_6_loss: 0.0214 - dense_2_7_loss: 0.0382 - dense_2_8_loss: 0.0789 - dense_2_9_loss: 0.1444 - dense_2_10_loss: 0.2452 - dense_2_11_loss: 0.3990 - dense_2_12_loss: 0.6368 - dense_2_13_loss: 0.8540 - dense_2_14_loss: 1.1149 - dense_2_15_loss: 1.1845 - dense_2_16_loss: 1.1118 - dense_2_17_loss: 0.9406 - dense_2_18_loss: 0.6088 - dense_2_19_loss: 0.4396 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9989 - dense_2_4_accuracy: 0.9982 - dense_2_5_accuracy: 0.9971 - dense_2_6_accuracy: 0.9933 - dense_2_7_accuracy: 0.9883 - dense_2_8_accuracy: 0.9770 - dense_2_9_accuracy: 0.9574 - dense_2_10_accuracy: 0.9248 - dense_2_11_accuracy: 0.8819 - dense_2_12_accuracy: 0.8186 - dense_2_13_accuracy: 0.7527 - dense_2_14_accuracy: 0.6588 - dense_2_15_accuracy: 0.6466 - dense_2_16_accuracy: 0.6538 - dense_2_17_accuracy: 0.7169 - dense_2_18_accuracy: 0.8202 - dense_2_19_accuracy: 0.8675\n",
            "Epoch 22/35\n",
            "171/171 [==============================] - 19s 112ms/step - loss: 6.9917 - dense_2_loss: 8.2227e-04 - dense_2_1_loss: 4.8401e-04 - dense_2_2_loss: 0.0018 - dense_2_3_loss: 0.0051 - dense_2_4_loss: 0.0065 - dense_2_5_loss: 0.0116 - dense_2_6_loss: 0.0214 - dense_2_7_loss: 0.0380 - dense_2_8_loss: 0.0671 - dense_2_9_loss: 0.1236 - dense_2_10_loss: 0.2193 - dense_2_11_loss: 0.3618 - dense_2_12_loss: 0.5729 - dense_2_13_loss: 0.7754 - dense_2_14_loss: 1.0332 - dense_2_15_loss: 1.1155 - dense_2_16_loss: 1.0226 - dense_2_17_loss: 0.8324 - dense_2_18_loss: 0.4817 - dense_2_19_loss: 0.3004 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9988 - dense_2_4_accuracy: 0.9985 - dense_2_5_accuracy: 0.9970 - dense_2_6_accuracy: 0.9938 - dense_2_7_accuracy: 0.9907 - dense_2_8_accuracy: 0.9803 - dense_2_9_accuracy: 0.9653 - dense_2_10_accuracy: 0.9344 - dense_2_11_accuracy: 0.8910 - dense_2_12_accuracy: 0.8330 - dense_2_13_accuracy: 0.7773 - dense_2_14_accuracy: 0.6976 - dense_2_15_accuracy: 0.6575 - dense_2_16_accuracy: 0.6877 - dense_2_17_accuracy: 0.7531 - dense_2_18_accuracy: 0.8582 - dense_2_19_accuracy: 0.9165\n",
            "Epoch 23/35\n",
            "171/171 [==============================] - 19s 113ms/step - loss: 7.5401 - dense_2_loss: 0.0012 - dense_2_1_loss: 0.0011 - dense_2_2_loss: 0.0019 - dense_2_3_loss: 0.0048 - dense_2_4_loss: 0.0046 - dense_2_5_loss: 0.0085 - dense_2_6_loss: 0.0162 - dense_2_7_loss: 0.0361 - dense_2_8_loss: 0.0656 - dense_2_9_loss: 0.1355 - dense_2_10_loss: 0.2315 - dense_2_11_loss: 0.3821 - dense_2_12_loss: 0.6053 - dense_2_13_loss: 0.8237 - dense_2_14_loss: 1.0993 - dense_2_15_loss: 1.1743 - dense_2_16_loss: 1.0978 - dense_2_17_loss: 0.9059 - dense_2_18_loss: 0.5602 - dense_2_19_loss: 0.3844 - dense_2_accuracy: 0.9999 - dense_2_1_accuracy: 0.9997 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9990 - dense_2_4_accuracy: 0.9984 - dense_2_5_accuracy: 0.9978 - dense_2_6_accuracy: 0.9957 - dense_2_7_accuracy: 0.9893 - dense_2_8_accuracy: 0.9801 - dense_2_9_accuracy: 0.9601 - dense_2_10_accuracy: 0.9338 - dense_2_11_accuracy: 0.8847 - dense_2_12_accuracy: 0.8242 - dense_2_13_accuracy: 0.7534 - dense_2_14_accuracy: 0.6738 - dense_2_15_accuracy: 0.6462 - dense_2_16_accuracy: 0.6665 - dense_2_17_accuracy: 0.7266 - dense_2_18_accuracy: 0.8332 - dense_2_19_accuracy: 0.8861\n",
            "Epoch 24/35\n",
            "171/171 [==============================] - 20s 114ms/step - loss: 6.1701 - dense_2_loss: 0.0012 - dense_2_1_loss: 5.4188e-04 - dense_2_2_loss: 0.0026 - dense_2_3_loss: 0.0048 - dense_2_4_loss: 0.0061 - dense_2_5_loss: 0.0083 - dense_2_6_loss: 0.0183 - dense_2_7_loss: 0.0351 - dense_2_8_loss: 0.0582 - dense_2_9_loss: 0.1115 - dense_2_10_loss: 0.1835 - dense_2_11_loss: 0.3184 - dense_2_12_loss: 0.5181 - dense_2_13_loss: 0.6615 - dense_2_14_loss: 0.9109 - dense_2_15_loss: 0.9808 - dense_2_16_loss: 0.9065 - dense_2_17_loss: 0.7104 - dense_2_18_loss: 0.4330 - dense_2_19_loss: 0.3006 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9991 - dense_2_4_accuracy: 0.9988 - dense_2_5_accuracy: 0.9978 - dense_2_6_accuracy: 0.9947 - dense_2_7_accuracy: 0.9909 - dense_2_8_accuracy: 0.9853 - dense_2_9_accuracy: 0.9682 - dense_2_10_accuracy: 0.9501 - dense_2_11_accuracy: 0.9069 - dense_2_12_accuracy: 0.8543 - dense_2_13_accuracy: 0.8121 - dense_2_14_accuracy: 0.7326 - dense_2_15_accuracy: 0.7139 - dense_2_16_accuracy: 0.7286 - dense_2_17_accuracy: 0.7850 - dense_2_18_accuracy: 0.8777 - dense_2_19_accuracy: 0.9140\n",
            "Epoch 25/35\n",
            "171/171 [==============================] - 19s 113ms/step - loss: 6.3665 - dense_2_loss: 0.0014 - dense_2_1_loss: 9.4157e-04 - dense_2_2_loss: 9.7527e-04 - dense_2_3_loss: 0.0067 - dense_2_4_loss: 0.0087 - dense_2_5_loss: 0.0167 - dense_2_6_loss: 0.0237 - dense_2_7_loss: 0.0409 - dense_2_8_loss: 0.0682 - dense_2_9_loss: 0.1227 - dense_2_10_loss: 0.2083 - dense_2_11_loss: 0.3288 - dense_2_12_loss: 0.5304 - dense_2_13_loss: 0.6832 - dense_2_14_loss: 0.9320 - dense_2_15_loss: 0.9953 - dense_2_16_loss: 0.9002 - dense_2_17_loss: 0.7302 - dense_2_18_loss: 0.4591 - dense_2_19_loss: 0.3080 - dense_2_accuracy: 0.9998 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9986 - dense_2_4_accuracy: 0.9984 - dense_2_5_accuracy: 0.9963 - dense_2_6_accuracy: 0.9935 - dense_2_7_accuracy: 0.9886 - dense_2_8_accuracy: 0.9813 - dense_2_9_accuracy: 0.9660 - dense_2_10_accuracy: 0.9402 - dense_2_11_accuracy: 0.9052 - dense_2_12_accuracy: 0.8494 - dense_2_13_accuracy: 0.8075 - dense_2_14_accuracy: 0.7311 - dense_2_15_accuracy: 0.7048 - dense_2_16_accuracy: 0.7334 - dense_2_17_accuracy: 0.7790 - dense_2_18_accuracy: 0.8773 - dense_2_19_accuracy: 0.9088\n",
            "Epoch 26/35\n",
            "171/171 [==============================] - 19s 114ms/step - loss: 5.9270 - dense_2_loss: 9.6620e-04 - dense_2_1_loss: 4.6591e-04 - dense_2_2_loss: 8.2370e-04 - dense_2_3_loss: 0.0036 - dense_2_4_loss: 0.0068 - dense_2_5_loss: 0.0090 - dense_2_6_loss: 0.0180 - dense_2_7_loss: 0.0377 - dense_2_8_loss: 0.0641 - dense_2_9_loss: 0.1104 - dense_2_10_loss: 0.1877 - dense_2_11_loss: 0.3024 - dense_2_12_loss: 0.4910 - dense_2_13_loss: 0.6345 - dense_2_14_loss: 0.8591 - dense_2_15_loss: 0.9565 - dense_2_16_loss: 0.8666 - dense_2_17_loss: 0.6853 - dense_2_18_loss: 0.4077 - dense_2_19_loss: 0.2844 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9994 - dense_2_4_accuracy: 0.9987 - dense_2_5_accuracy: 0.9977 - dense_2_6_accuracy: 0.9949 - dense_2_7_accuracy: 0.9900 - dense_2_8_accuracy: 0.9803 - dense_2_9_accuracy: 0.9692 - dense_2_10_accuracy: 0.9479 - dense_2_11_accuracy: 0.9112 - dense_2_12_accuracy: 0.8565 - dense_2_13_accuracy: 0.8191 - dense_2_14_accuracy: 0.7499 - dense_2_15_accuracy: 0.7157 - dense_2_16_accuracy: 0.7354 - dense_2_17_accuracy: 0.7986 - dense_2_18_accuracy: 0.8865 - dense_2_19_accuracy: 0.9168\n",
            "Epoch 27/35\n",
            "171/171 [==============================] - 20s 114ms/step - loss: 6.0392 - dense_2_loss: 8.2865e-04 - dense_2_1_loss: 4.3861e-04 - dense_2_2_loss: 4.1289e-04 - dense_2_3_loss: 0.0025 - dense_2_4_loss: 0.0076 - dense_2_5_loss: 0.0120 - dense_2_6_loss: 0.0225 - dense_2_7_loss: 0.0355 - dense_2_8_loss: 0.0632 - dense_2_9_loss: 0.1055 - dense_2_10_loss: 0.1874 - dense_2_11_loss: 0.2984 - dense_2_12_loss: 0.4767 - dense_2_13_loss: 0.6400 - dense_2_14_loss: 0.8882 - dense_2_15_loss: 0.9513 - dense_2_16_loss: 0.8758 - dense_2_17_loss: 0.7246 - dense_2_18_loss: 0.4418 - dense_2_19_loss: 0.3043 - dense_2_accuracy: 0.9999 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9992 - dense_2_4_accuracy: 0.9982 - dense_2_5_accuracy: 0.9971 - dense_2_6_accuracy: 0.9936 - dense_2_7_accuracy: 0.9899 - dense_2_8_accuracy: 0.9823 - dense_2_9_accuracy: 0.9700 - dense_2_10_accuracy: 0.9441 - dense_2_11_accuracy: 0.9181 - dense_2_12_accuracy: 0.8603 - dense_2_13_accuracy: 0.8199 - dense_2_14_accuracy: 0.7375 - dense_2_15_accuracy: 0.7127 - dense_2_16_accuracy: 0.7372 - dense_2_17_accuracy: 0.7790 - dense_2_18_accuracy: 0.8788 - dense_2_19_accuracy: 0.9101\n",
            "Epoch 28/35\n",
            "171/171 [==============================] - 20s 115ms/step - loss: 5.8064 - dense_2_loss: 8.4422e-04 - dense_2_1_loss: 4.4023e-04 - dense_2_2_loss: 4.3386e-04 - dense_2_3_loss: 0.0042 - dense_2_4_loss: 0.0046 - dense_2_5_loss: 0.0078 - dense_2_6_loss: 0.0181 - dense_2_7_loss: 0.0347 - dense_2_8_loss: 0.0639 - dense_2_9_loss: 0.1135 - dense_2_10_loss: 0.1958 - dense_2_11_loss: 0.3131 - dense_2_12_loss: 0.4783 - dense_2_13_loss: 0.6410 - dense_2_14_loss: 0.8431 - dense_2_15_loss: 0.9194 - dense_2_16_loss: 0.8191 - dense_2_17_loss: 0.6667 - dense_2_18_loss: 0.3955 - dense_2_19_loss: 0.2859 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 0.9990 - dense_2_4_accuracy: 0.9987 - dense_2_5_accuracy: 0.9979 - dense_2_6_accuracy: 0.9943 - dense_2_7_accuracy: 0.9903 - dense_2_8_accuracy: 0.9833 - dense_2_9_accuracy: 0.9688 - dense_2_10_accuracy: 0.9470 - dense_2_11_accuracy: 0.9111 - dense_2_12_accuracy: 0.8622 - dense_2_13_accuracy: 0.8195 - dense_2_14_accuracy: 0.7561 - dense_2_15_accuracy: 0.7237 - dense_2_16_accuracy: 0.7573 - dense_2_17_accuracy: 0.8032 - dense_2_18_accuracy: 0.8923 - dense_2_19_accuracy: 0.9146\n",
            "Epoch 29/35\n",
            "171/171 [==============================] - 20s 116ms/step - loss: 5.5812 - dense_2_loss: 7.2018e-04 - dense_2_1_loss: 1.3435e-04 - dense_2_2_loss: 0.0024 - dense_2_3_loss: 0.0033 - dense_2_4_loss: 0.0067 - dense_2_5_loss: 0.0085 - dense_2_6_loss: 0.0192 - dense_2_7_loss: 0.0406 - dense_2_8_loss: 0.0600 - dense_2_9_loss: 0.1185 - dense_2_10_loss: 0.1913 - dense_2_11_loss: 0.3018 - dense_2_12_loss: 0.4563 - dense_2_13_loss: 0.6216 - dense_2_14_loss: 0.8323 - dense_2_15_loss: 0.8769 - dense_2_16_loss: 0.8031 - dense_2_17_loss: 0.6150 - dense_2_18_loss: 0.3659 - dense_2_19_loss: 0.2570 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 1.0000 - dense_2_2_accuracy: 0.9998 - dense_2_3_accuracy: 0.9992 - dense_2_4_accuracy: 0.9981 - dense_2_5_accuracy: 0.9975 - dense_2_6_accuracy: 0.9943 - dense_2_7_accuracy: 0.9890 - dense_2_8_accuracy: 0.9847 - dense_2_9_accuracy: 0.9676 - dense_2_10_accuracy: 0.9481 - dense_2_11_accuracy: 0.9104 - dense_2_12_accuracy: 0.8662 - dense_2_13_accuracy: 0.8228 - dense_2_14_accuracy: 0.7498 - dense_2_15_accuracy: 0.7416 - dense_2_16_accuracy: 0.7578 - dense_2_17_accuracy: 0.8196 - dense_2_18_accuracy: 0.9006 - dense_2_19_accuracy: 0.9250\n",
            "Epoch 30/35\n",
            "171/171 [==============================] - 20s 117ms/step - loss: 5.4710 - dense_2_loss: 8.9595e-04 - dense_2_1_loss: 9.7558e-04 - dense_2_2_loss: 9.7638e-04 - dense_2_3_loss: 0.0034 - dense_2_4_loss: 0.0083 - dense_2_5_loss: 0.0114 - dense_2_6_loss: 0.0198 - dense_2_7_loss: 0.0382 - dense_2_8_loss: 0.0558 - dense_2_9_loss: 0.1026 - dense_2_10_loss: 0.1737 - dense_2_11_loss: 0.2734 - dense_2_12_loss: 0.4420 - dense_2_13_loss: 0.6168 - dense_2_14_loss: 0.8172 - dense_2_15_loss: 0.8743 - dense_2_16_loss: 0.7764 - dense_2_17_loss: 0.5993 - dense_2_18_loss: 0.3783 - dense_2_19_loss: 0.2773 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9997 - dense_2_2_accuracy: 0.9999 - dense_2_3_accuracy: 0.9991 - dense_2_4_accuracy: 0.9981 - dense_2_5_accuracy: 0.9956 - dense_2_6_accuracy: 0.9938 - dense_2_7_accuracy: 0.9895 - dense_2_8_accuracy: 0.9840 - dense_2_9_accuracy: 0.9725 - dense_2_10_accuracy: 0.9517 - dense_2_11_accuracy: 0.9229 - dense_2_12_accuracy: 0.8724 - dense_2_13_accuracy: 0.8229 - dense_2_14_accuracy: 0.7554 - dense_2_15_accuracy: 0.7490 - dense_2_16_accuracy: 0.7720 - dense_2_17_accuracy: 0.8258 - dense_2_18_accuracy: 0.8950 - dense_2_19_accuracy: 0.9214\n",
            "Epoch 31/35\n",
            "171/171 [==============================] - 20s 115ms/step - loss: 5.3949 - dense_2_loss: 9.1111e-04 - dense_2_1_loss: 4.0817e-04 - dense_2_2_loss: 7.2980e-04 - dense_2_3_loss: 0.0035 - dense_2_4_loss: 0.0073 - dense_2_5_loss: 0.0123 - dense_2_6_loss: 0.0221 - dense_2_7_loss: 0.0399 - dense_2_8_loss: 0.0602 - dense_2_9_loss: 0.1015 - dense_2_10_loss: 0.1659 - dense_2_11_loss: 0.2789 - dense_2_12_loss: 0.4344 - dense_2_13_loss: 0.6094 - dense_2_14_loss: 0.8145 - dense_2_15_loss: 0.8562 - dense_2_16_loss: 0.7593 - dense_2_17_loss: 0.5957 - dense_2_18_loss: 0.3656 - dense_2_19_loss: 0.2660 - dense_2_accuracy: 0.9998 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 1.0000 - dense_2_3_accuracy: 0.9992 - dense_2_4_accuracy: 0.9979 - dense_2_5_accuracy: 0.9972 - dense_2_6_accuracy: 0.9939 - dense_2_7_accuracy: 0.9891 - dense_2_8_accuracy: 0.9838 - dense_2_9_accuracy: 0.9717 - dense_2_10_accuracy: 0.9529 - dense_2_11_accuracy: 0.9183 - dense_2_12_accuracy: 0.8727 - dense_2_13_accuracy: 0.8233 - dense_2_14_accuracy: 0.7633 - dense_2_15_accuracy: 0.7453 - dense_2_16_accuracy: 0.7808 - dense_2_17_accuracy: 0.8207 - dense_2_18_accuracy: 0.8918 - dense_2_19_accuracy: 0.9224\n",
            "Epoch 32/35\n",
            "171/171 [==============================] - 20s 115ms/step - loss: 5.2011 - dense_2_loss: 5.6476e-04 - dense_2_1_loss: 4.0255e-04 - dense_2_2_loss: 0.0033 - dense_2_3_loss: 0.0058 - dense_2_4_loss: 0.0101 - dense_2_5_loss: 0.0147 - dense_2_6_loss: 0.0226 - dense_2_7_loss: 0.0375 - dense_2_8_loss: 0.0614 - dense_2_9_loss: 0.1025 - dense_2_10_loss: 0.1626 - dense_2_11_loss: 0.2845 - dense_2_12_loss: 0.4400 - dense_2_13_loss: 0.5786 - dense_2_14_loss: 0.7684 - dense_2_15_loss: 0.8035 - dense_2_16_loss: 0.7139 - dense_2_17_loss: 0.5818 - dense_2_18_loss: 0.3352 - dense_2_19_loss: 0.2736 - dense_2_accuracy: 0.9999 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9988 - dense_2_4_accuracy: 0.9983 - dense_2_5_accuracy: 0.9966 - dense_2_6_accuracy: 0.9942 - dense_2_7_accuracy: 0.9900 - dense_2_8_accuracy: 0.9838 - dense_2_9_accuracy: 0.9737 - dense_2_10_accuracy: 0.9563 - dense_2_11_accuracy: 0.9182 - dense_2_12_accuracy: 0.8720 - dense_2_13_accuracy: 0.8366 - dense_2_14_accuracy: 0.7682 - dense_2_15_accuracy: 0.7598 - dense_2_16_accuracy: 0.7902 - dense_2_17_accuracy: 0.8369 - dense_2_18_accuracy: 0.9078 - dense_2_19_accuracy: 0.9221\n",
            "Epoch 33/35\n",
            "171/171 [==============================] - 20s 114ms/step - loss: 4.7810 - dense_2_loss: 7.1396e-04 - dense_2_1_loss: 8.1113e-04 - dense_2_2_loss: 0.0020 - dense_2_3_loss: 0.0020 - dense_2_4_loss: 0.0054 - dense_2_5_loss: 0.0095 - dense_2_6_loss: 0.0194 - dense_2_7_loss: 0.0381 - dense_2_8_loss: 0.0597 - dense_2_9_loss: 0.0991 - dense_2_10_loss: 0.1759 - dense_2_11_loss: 0.2660 - dense_2_12_loss: 0.3978 - dense_2_13_loss: 0.5457 - dense_2_14_loss: 0.7132 - dense_2_15_loss: 0.7449 - dense_2_16_loss: 0.6659 - dense_2_17_loss: 0.5089 - dense_2_18_loss: 0.2939 - dense_2_19_loss: 0.2322 - dense_2_accuracy: 0.9999 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9994 - dense_2_4_accuracy: 0.9988 - dense_2_5_accuracy: 0.9974 - dense_2_6_accuracy: 0.9952 - dense_2_7_accuracy: 0.9894 - dense_2_8_accuracy: 0.9833 - dense_2_9_accuracy: 0.9732 - dense_2_10_accuracy: 0.9531 - dense_2_11_accuracy: 0.9286 - dense_2_12_accuracy: 0.8838 - dense_2_13_accuracy: 0.8385 - dense_2_14_accuracy: 0.7842 - dense_2_15_accuracy: 0.7841 - dense_2_16_accuracy: 0.8072 - dense_2_17_accuracy: 0.8479 - dense_2_18_accuracy: 0.9221 - dense_2_19_accuracy: 0.9364\n",
            "Epoch 34/35\n",
            "171/171 [==============================] - 19s 114ms/step - loss: 4.5141 - dense_2_loss: 7.3561e-04 - dense_2_1_loss: 1.8253e-04 - dense_2_2_loss: 0.0023 - dense_2_3_loss: 0.0031 - dense_2_4_loss: 0.0055 - dense_2_5_loss: 0.0128 - dense_2_6_loss: 0.0203 - dense_2_7_loss: 0.0380 - dense_2_8_loss: 0.0514 - dense_2_9_loss: 0.0991 - dense_2_10_loss: 0.1497 - dense_2_11_loss: 0.2408 - dense_2_12_loss: 0.3690 - dense_2_13_loss: 0.5033 - dense_2_14_loss: 0.6819 - dense_2_15_loss: 0.7273 - dense_2_16_loss: 0.6448 - dense_2_17_loss: 0.4919 - dense_2_18_loss: 0.2765 - dense_2_19_loss: 0.1955 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9999 - dense_2_2_accuracy: 0.9997 - dense_2_3_accuracy: 0.9993 - dense_2_4_accuracy: 0.9988 - dense_2_5_accuracy: 0.9971 - dense_2_6_accuracy: 0.9940 - dense_2_7_accuracy: 0.9890 - dense_2_8_accuracy: 0.9873 - dense_2_9_accuracy: 0.9755 - dense_2_10_accuracy: 0.9588 - dense_2_11_accuracy: 0.9323 - dense_2_12_accuracy: 0.8898 - dense_2_13_accuracy: 0.8542 - dense_2_14_accuracy: 0.8035 - dense_2_15_accuracy: 0.7871 - dense_2_16_accuracy: 0.8111 - dense_2_17_accuracy: 0.8534 - dense_2_18_accuracy: 0.9232 - dense_2_19_accuracy: 0.9416\n",
            "Epoch 35/35\n",
            "171/171 [==============================] - 20s 115ms/step - loss: 5.4441 - dense_2_loss: 3.6731e-04 - dense_2_1_loss: 6.1323e-04 - dense_2_2_loss: 0.0020 - dense_2_3_loss: 0.0039 - dense_2_4_loss: 0.0057 - dense_2_5_loss: 0.0104 - dense_2_6_loss: 0.0230 - dense_2_7_loss: 0.0460 - dense_2_8_loss: 0.0667 - dense_2_9_loss: 0.1131 - dense_2_10_loss: 0.1845 - dense_2_11_loss: 0.2998 - dense_2_12_loss: 0.4329 - dense_2_13_loss: 0.5869 - dense_2_14_loss: 0.7914 - dense_2_15_loss: 0.8519 - dense_2_16_loss: 0.7318 - dense_2_17_loss: 0.6032 - dense_2_18_loss: 0.3734 - dense_2_19_loss: 0.3163 - dense_2_accuracy: 1.0000 - dense_2_1_accuracy: 0.9998 - dense_2_2_accuracy: 0.9996 - dense_2_3_accuracy: 0.9984 - dense_2_4_accuracy: 0.9984 - dense_2_5_accuracy: 0.9968 - dense_2_6_accuracy: 0.9940 - dense_2_7_accuracy: 0.9879 - dense_2_8_accuracy: 0.9828 - dense_2_9_accuracy: 0.9713 - dense_2_10_accuracy: 0.9464 - dense_2_11_accuracy: 0.9153 - dense_2_12_accuracy: 0.8741 - dense_2_13_accuracy: 0.8294 - dense_2_14_accuracy: 0.7618 - dense_2_15_accuracy: 0.7455 - dense_2_16_accuracy: 0.7854 - dense_2_17_accuracy: 0.8279 - dense_2_18_accuracy: 0.8941 - dense_2_19_accuracy: 0.9070\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f298aa286d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C2RET9GwXDh"
      },
      "source": [
        "# Thai-Script to Roman-Script Translation\n",
        "* Task 4: Test your model on 5 examples of your choice including your name! (1 point)\n",
        "* Task 5: Show your visualization of attention scores on one of your example (1 point)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gON7T2xVwXDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59cca089-2d96-477c-ff5e-d9e2cdca5571"
      },
      "source": [
        "#task 4\n",
        "#fill your code here\n",
        "def prep_input(input_list):\n",
        "    prep = []\n",
        "    for line in input_list:\n",
        "        temp = []\n",
        "        for char in line:\n",
        "            temp.append(inputchar2idx[char])\n",
        "        prep.append(temp)\n",
        "    prep = pad_sequences(prep, maxlen=max_input)\n",
        "    prep = to_categorical(prep, len(inputchar2idx))\n",
        "    return prep\n",
        "\n",
        "EXAMPLES = [\"กรวิช\", \"สุชัญญา\", \"กริส\", \"คริส\", \"คริษฐ์\"]\n",
        "\n",
        "s0 = np.zeros((len(EXAMPLES), n_s))\n",
        "c0 = np.zeros((len(EXAMPLES), n_s))\n",
        "prep = prep_input(EXAMPLES)\n",
        "\n",
        "pred_a = model.predict([prep, s0, c0])\n",
        "pred_b = np.swapaxes(pred_a, 0, 1)\n",
        "pred = np.argmax(pred_b, axis=-1)\n",
        "for j in range(len(pred)):\n",
        "    output = (\"\".join([idx2outputchar[int(i)] for i in pred[j]])).strip(\"<PAD>\")\n",
        "    print('in nameth:', EXAMPLES[j] in name_th, EXAMPLES[j], '=>', output)\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in nameth: False กรวิช => konwit\n",
            "in nameth: False สุชัญญา => suchanya\n",
            "in nameth: False กริส => krrit\n",
            "in nameth: True คริส => khrrit\n",
            "in nameth: False คริษฐ์ => hrrit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9-mxbsKwXDp"
      },
      "source": [
        "### Plot the attention map\n",
        "* If you need to install thai font: sudo apt install xfonts-thai\n",
        "* this is what your visualization might look like:\n",
        "<img src=\"https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/attn_viz_sample.png\"  style=\"width: 350px;\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRL8hHaLwXDq"
      },
      "source": [
        "#task 5\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['font.family']='TH Sarabun New'  #you can change to other font that works for you\n",
        "#fill your code here\n",
        "model_att = Model(inputs=model.inputs, outputs=[model.outputs, [model.get_layer('attention_scores').get_output_at(e) for e in range(max_output)]])"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWhBo6YeouA6",
        "outputId": "10b4a539-f3ff-4045-eb93-d0f81c1f305a"
      },
      "source": [
        "EXAMPLES_NAME = \"คริษฐ์\"\n",
        "EXAMPLES_NAME_pad = [\"<PAD>\" for i in range(max_input-len(EXAMPLES_NAME))] + list(EXAMPLES_NAME)\n",
        "\n",
        "prep_name = prep_input([EXAMPLES_NAME])\n",
        "s0 = np.zeros((len(prep_name), n_s))\n",
        "c0 = np.zeros((len(prep_name), n_s))\n",
        "\n",
        "pred_name = model_att.predict([prep_name, s0, c0])\n",
        "\n",
        "pred_name_out = np.swapaxes(pred_name[0], 0, 1)\n",
        "pred_name_out = np.argmax(pred_name_out, axis=-1)\n",
        "\n",
        "output = [idx2outputchar[int(i)] for i in pred_name_out[0]]\n",
        "print(\"\".join(EXAMPLES_NAME_pad))\n",
        "print(''.join(output))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>คริษฐ์\n",
            "<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>khirit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "3X9KZsqXovkS",
        "outputId": "4b23ca0a-a229-4bca-d633-5555b5480513"
      },
      "source": [
        "att_score = np.array(pred_name[1]).reshape(20,20)\n",
        "\n",
        "sns.heatmap(att_score, xticklabels=EXAMPLES_NAME_pad, yticklabels=output ,linewidths=0.01)\n",
        "plt.show()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-kDGPv0tsklG",
        "outputId": "06133d97-33c4-45ce-a7c6-9297724c398e"
      },
      "source": [
        "\"why 55555\""
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'why 55555'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkYc2cmg3Xqs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}